# Servers.
conductor.grpc-server.enabled=false

# Database persistence type.
conductor.db.type=dynomite

# Dynomite Cluster details.
# format is host:port:rack separated by semicolon
conductor.redis.hosts=dyno1:8102:us-east-1c

# Dynomite cluster name
conductor.redis.clusterName=dyno1

# Namespace for the keys stored in Dynomite/Redis
conductor.redis.workflowNamespacePrefix=conductor

# Namespace prefix for the dyno queues
conductor.redis.queueNamespacePrefix=conductor_queues

# No. of threads allocated to dyno-queues (optional)
queues.dynomite.threads=10

# By default with dynomite, we want the repairservice enabled
conductor.app.workflowRepairServiceEnabled=true

# Non-quorum port used to connect to local redis.  Used by dyno-queues.
# When using redis directly, set this to the same port as redis server
# For Dynomite, this is 22122 by default or the local redis-server port used by Dynomite.
conductor.redis.queuesNonQuorumPort=22122

# Elastic search instance indexing is enabled.
conductor.indexing.enabled=true

# Transport address to elasticsearch
conductor.elasticsearch.url=http://es:9200

# Name of the elasticsearch cluster
conductor.elasticsearch.indexName=conductor

# Additional modules for metrics collection exposed via logger (optional)
# conductor.metrics-logger.enabled=true
# conductor.metrics-logger.reportPeriodSeconds=15

# Additional modules for metrics collection exposed to Prometheus (optional)
# conductor.metrics-prometheus.enabled=true
# management.endpoints.web.exposure.include=prometheus

# To enable Workflow/Task Summary Input/Output JSON Serialization, use the following:
# conductor.app.summary-input-output-json-serialization.enabled=true

# Load sample kitchen sink workflow
loadSample=true
